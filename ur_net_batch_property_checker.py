#!/usr/bin/env python3
"""
UR-NET ãƒãƒƒãƒç©ºå®¤ãƒã‚§ãƒƒã‚¯ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
ur_net_single_property_scraper.py ã‚’åŸºã«ã—ãŸãƒãƒƒãƒå‡¦ç†ç‰ˆ
è¤‡æ•°ã®URLã‚’å‡¦ç†ã—ã€èª­ã¿ã‚„ã™ã„çµæœã‚’å‡ºåŠ›ã‚’ã‚µãƒãƒ¼ãƒˆ
"""

import asyncio
import sys
import json
import re
import time
import argparse
import csv
import logging
import os
import glob
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from playwright.async_api import async_playwright

class URNetBatchChecker:
    def __init__(self, delay_seconds: float = 2.0, max_retries: int = 5, headless: bool = True):
        """
        ãƒãƒƒãƒãƒã‚§ãƒƒã‚«ãƒ¼ã‚’åˆæœŸåŒ–
        
        Args:
            delay_seconds: ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã®é…å»¶æ™‚é–“ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
            headless: ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        """
        self.delay_seconds = delay_seconds
        self.max_retries = max_retries
        self.headless = headless
        self.results = []
        
    async def extract_property_info(self, page, url: str, predefined_info: Optional[Dict] = None) -> Dict:
        """
        ãƒšãƒ¼ã‚¸ã‹ã‚‰ç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡º
        
        Args:
            page: Playwrightãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            url: å¯¾è±¡URL
            predefined_info: äº‹å‰å®šç¾©ã•ã‚ŒãŸç‰©ä»¶æƒ…å ±ï¼ˆCSVã‹ã‚‰ï¼‰
            
        Returns:
            ç‰©ä»¶æƒ…å ±ã‚’å«ã‚€è¾æ›¸
        """
        try:
            # ç‰©ä»¶åã‚’æŠ½å‡º
            try:
                name_element = await page.query_selector('h1.property-name')
                if name_element:
                    name = await name_element.text_content()
                    property_name = name.strip() if name else "ä¸æ˜ãªç‰©ä»¶"
                else:
                    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œ
                    name_element = await page.query_selector('h1, .property-title, .building-name')
                    if name_element:
                        name = await name_element.text_content()
                        property_name = name.strip() if name else "ä¸æ˜ãªç‰©ä»¶"
                    else:
                        property_name = predefined_info.get('name', 'ä¸æ˜ãªç‰©ä»¶') if predefined_info else "ä¸æ˜ãªç‰©ä»¶"
            except Exception as e:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡º
                title = await page.title()
                property_name = title.replace("ï¼ˆæ±äº¬éƒ½ï¼‰ã®è³ƒè²¸ç‰©ä»¶ï½œURè³ƒè²¸ä½å®…", "").strip()
                if not property_name:
                    property_name = predefined_info.get('name', 'ä¸æ˜ãªç‰©ä»¶') if predefined_info else "ä¸æ˜ãªç‰©ä»¶"
            
            # ç©ºå®¤æƒ…å ±ã‚’æ¤œç´¢ - UR-NETå°‚ç”¨ã®æ”¹è‰¯ã•ã‚ŒãŸãƒ­ã‚¸ãƒƒã‚¯
            import re  # æ˜ç¤ºçš„ã«reãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            vacant_rooms = []
            
            # UR-NETã®æˆ¿é—´è¡¨æ ¼ã‚’ç‰¹å®š - è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œ
            room_table_selectors = [
                '.module_tables_room table tbody tr.js-log-item',  # UR-NETç‰¹æœ‰ã®ã‚»ãƒ¬ã‚¯ã‚¿
                'table tbody tr.js-log-item',  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                '.rep_room',  # åˆ¥ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                'table tbody tr',  # ä¸€èˆ¬çš„ãªãƒ†ãƒ¼ãƒ–ãƒ«è¡Œ
                'tr',  # æœ€ã‚‚ä¸€èˆ¬çš„
            ]
            
            room_rows = []
            for selector in room_table_selectors:
                try:
                    rows = await page.query_selector_all(selector)
                    if rows:
                        # æˆ¿é—´æƒ…å ±ã‚’å«ã‚€è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - ã‚ˆã‚Šå³æ ¼ãªæ¡ä»¶
                        filtered_rows = []
                        for row in rows:
                            try:
                                row_text = await row.text_content()
                                # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤å¤–
                                if row_text and not any(header in row_text for header in 
                                    ['é–“å–å›³', 'éƒ¨å±‹å', 'å®¶è³ƒ', 'é–“å–ã‚Š', 'åºŠé¢ç©', 'éšæ•°']):
                                    # æˆ¿é—´æƒ…å ±ã‚‰ã—ã„è¡Œã‚’ç‰¹å®š - ä¾¡æ ¼ã¨æˆ¿é—´å/é–“å–ã‚Šã®ä¸¡æ–¹ãŒå¿…è¦
                                    has_price = re.search(r'\d{1,3}[,ï¼Œ]\d{3}[å††æ—¥å…ƒ]?', row_text)
                                    has_room_info = (re.search(r'\d+[å·æ£Ÿå®¤]', row_text) or  # æˆ¿é—´åãƒ‘ã‚¿ãƒ¼ãƒ³
                                                   re.search(r'\d+[LDK]', row_text))  # é–“å–ã‚Šãƒ‘ã‚¿ãƒ¼ãƒ³
                                    
                                    if has_price and has_room_info:
                                        filtered_rows.append(row)
                            except:
                                continue
                        
                        if filtered_rows:
                            room_rows = filtered_rows
                            print(f"âœ… æˆ¿é—´è¡Œã‚’ç™ºè¦‹: {len(filtered_rows)}è¡Œ (ã‚»ãƒ¬ã‚¯ã‚¿: {selector})")
                            break
                except:
                    continue
            
            if not room_rows:
                print("âš ï¸ æˆ¿é—´æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            for row in room_rows:
                try:
                    # UR-NETç‰¹æœ‰ã®æ§‹é€ ã«åŸºã¥ã„ã¦æƒ…å ±ã‚’æŠ½å‡º
                    room_info = {}
                    
                    # æˆ¿é—´åã‚’æŠ½å‡º - ã‚ˆã‚ŠæŸ”è»Ÿãªã‚»ãƒ¬ã‚¯ã‚¿
                    room_name_selectors = [
                        '.rep_room-name',
                        'td.rep_room-name', 
                        'td:nth-child(2)',  # é€šå¸¸2ç•ªç›®ã®ã‚»ãƒ«
                        'td:first-child + td',  # æœ€åˆã®ã‚»ãƒ«ã®æ¬¡
                    ]
                    
                    room_name = None
                    for selector in room_name_selectors:
                        try:
                            element = await row.query_selector(selector)
                            if element:
                                room_name = await element.text_content()
                                if room_name and room_name.strip():
                                    room_name = room_name.strip()
                                    # æˆ¿é—´åã‚‰ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                                    if re.search(r'\d+[å·æ£Ÿå®¤]', room_name):
                                        break
                        except:
                            continue
                    
                    # æˆ¿é—´åãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€è¡Œå…¨ä½“ã‹ã‚‰æŠ½å‡ºã‚’è©¦è¡Œ
                    if not room_name:
                        try:
                            row_text = await row.text_content()
                            if row_text:
                                # æˆ¿é—´åãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                                room_name_match = re.search(r'(\d+[å·æ£Ÿ]\d+[å·å®¤])', row_text)
                                if room_name_match:
                                    room_name = room_name_match.group(1)
                        except:
                            pass
                    
                    # ä¾¡æ ¼ã‚’æŠ½å‡º - ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªã‚»ãƒ¬ã‚¯ã‚¿
                    price_selectors = [
                        'span.rep_room-price',  # ä¸»è¦ä»·æ ¼é€‰æ‹©å™¨
                        '.rep_room-price',
                        'td:nth-child(3) span.rep_room-price',
                        'td:nth-child(3)',
                        'td:nth-child(4)',  # å ´åˆã«ã‚ˆã£ã¦ã¯4ç•ªç›®ã®ã‚»ãƒ«
                    ]
                    
                    rent = None
                    for selector in price_selectors:
                        try:
                            element = await row.query_selector(selector)
                            if element:
                                rent = await element.text_content()
                                if rent and rent.strip():
                                    rent = rent.strip()
                                    # ä¾¡æ ¼ã‚‰ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                                    if re.search(r'\d{1,3}[,ï¼Œ]\d{3}', rent):
                                        break
                        except:
                            continue
                    
                    # ä¾¡æ ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€è¡Œå…¨ä½“ã‹ã‚‰æŠ½å‡ºã‚’è©¦è¡Œ
                    if not rent:
                        try:
                            row_text = await row.text_content()
                            if row_text:
                                # ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                                price_match = re.search(r'(\d{1,3}[,ï¼Œ]\d{3}[å††æ—¥å…ƒ]?)', row_text)
                                if price_match:
                                    rent = price_match.group(1)
                        except:
                            pass
                    
                    # é–“å–ã‚Šæƒ…å ±ã‚’æŠ½å‡º - UR-NETè¡¨æ ¼æ§‹é€ ã«åŸºã¥ã
                    type_selectors = [
                        'td:nth-child(4)',  # é€šå¸¸é–“å–ã‚Šã¯4ç•ªç›®ã®ã‚»ãƒ«
                        'td:nth-child(3)',  # å ´åˆã«ã‚ˆã£ã¦ã¯3ç•ªç›®
                        'td:nth-child(5)',  # å ´åˆã«ã‚ˆã£ã¦ã¯5ç•ªç›®
                        '.rep_room-type',
                        'td.rep_room-type',
                    ]
                    
                    room_type = None
                    for selector in type_selectors:
                        try:
                            element = await row.query_selector(selector)
                            if element:
                                text = await element.text_content()
                                if text and text.strip():
                                    text = text.strip()
                                    # é–“å–ã‚Šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ˆã‚ŠåŒ…æ‹¬çš„ï¼‰
                                    type_match = re.search(r'(\d+[SLDK]+)', text)
                                    if type_match:
                                        room_type = type_match.group(1)
                                        break
                        except:
                            continue
                    
                    # é–“å–ã‚ŠãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€è¡Œå…¨ä½“ã‹ã‚‰æŠ½å‡ºã‚’è©¦è¡Œ
                    if not room_type:
                        try:
                            row_text = await row.text_content()
                            if row_text:
                                # ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªé–“å–ã‚Šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                                type_match = re.search(r'(\d+[SLDK]+)', row_text)
                                if type_match:
                                    room_type = type_match.group(1)
                        except:
                            pass
                    
                    # é¢ç©ã‚’æŠ½å‡º - ã‚ˆã‚ŠåŒ…æ‹¬çš„
                    area_selectors = [
                        '.rep_room-floor',
                        'td.rep_room-floor',
                        'td:nth-child(5)',
                        'td:nth-child(6)',
                    ]
                    
                    area = None
                    for selector in area_selectors:
                        try:
                            element = await row.query_selector(selector)
                            if element:
                                area = await element.text_content()
                                if area and area.strip():
                                    area = area.strip()
                                    # é¢ç©ã‚‰ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                                    if re.search(r'\d+[ã¡å¹³æ–¹ç±³]', area):
                                        break
                        except:
                            continue
                    
                    # é¢ç©ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€è¡Œå…¨ä½“ã‹ã‚‰æŠ½å‡ºã‚’è©¦è¡Œ
                    if not area:
                        try:
                            row_text = await row.text_content()
                            if row_text:
                                # é¢ç©ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                                area_match = re.search(r'(\d+[ã¡å¹³æ–¹ç±³])', row_text)
                                if area_match:
                                    area = area_match.group(1)
                        except:
                            pass
                    
                    # æ¥¼å±¤æƒ…å ±ã‚’æŠ½å‡º - ã‚ˆã‚ŠåŒ…æ‹¬çš„
                    floor_selectors = [
                        '.rep_room-kai',
                        'td.rep_room-kai',
                        'td:nth-child(6)',
                        'td:nth-child(7)',
                        'td:last-child',
                    ]
                    
                    floor = None
                    for selector in floor_selectors:
                        try:
                            element = await row.query_selector(selector)
                            if element:
                                floor = await element.text_content()
                                if floor and floor.strip():
                                    floor = floor.strip()
                                    # éšå±¤ã‚‰ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                                    if re.search(r'\d+[éš]', floor) or '/' in floor:
                                        break
                        except:
                            continue
                    
                    # éšå±¤ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€è¡Œå…¨ä½“ã‹ã‚‰æŠ½å‡ºã‚’è©¦è¡Œ
                    if not floor:
                        try:
                            row_text = await row.text_content()
                            if row_text:
                                # éšå±¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                                floor_match = re.search(r'(\d+[éš]ï¼?\d*[éš]?)', row_text)
                                if floor_match:
                                    floor = floor_match.group(1)
                        except:
                            pass
                    
                    # ç©ºå®¤åˆ¤å®š - ç°¡æ½”ãªãƒ­ã‚¸ãƒƒã‚¯
                    # æˆ¿é—´æƒ…å ±è¡¨æ ¼ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹æˆ¿é—´ã¯åŸºæœ¬çš„ã«ç©ºå®¤ã¨ã¿ãªã™
                    # ï¼ˆUR-NETã§ã¯ç©ºå®¤ã®ã¿è©³ç´°æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ç‰¹æ€§ã‚’åˆ©ç”¨ï¼‰
                    is_vacant = False
                    
                    # è©³ç´°ãƒœã‚¿ãƒ³ã®å­˜åœ¨ã‚’ãƒã‚§ãƒƒã‚¯
                    try:
                        detail_button = await row.query_selector('a')
                        if detail_button:
                            button_text = await detail_button.text_content()
                            button_href = await detail_button.get_attribute('href')
                            # è©³ç´°ãƒœã‚¿ãƒ³ãŒã‚ã‚Œã°ç©ºå®¤
                            if (button_text and 'è©³ç´°' in button_text) or \
                               (button_href and 'room.html' in button_href):
                                is_vacant = True
                    except:
                        pass
                    
                    # è©³ç´°ãƒœã‚¿ãƒ³ãŒãªãã¦ã‚‚ã€ä¾¡æ ¼ã¨é–“å–ã‚Šæƒ…å ±ãŒã‚ã‚Œã°ç©ºå®¤ã¨ã¿ãªã™
                    if not is_vacant and rent and room_type:
                        is_vacant = True
                    
                    # æœ‰åŠ¹ãªæˆ¿é—´æƒ…å ±ãŒã‚ã‚‹å ´åˆã«è¿½åŠ ï¼ˆç‰©ä»¶åã¯é™¤å¤–ï¼‰
                    if is_vacant and (room_type and rent):
                        room_info = {
                            'type': room_type or 'ä¸æ˜', 
                            'rent': rent or 'ä¸æ˜',
                            'area': area or 'ä¸æ˜',
                            'floor': floor or 'ä¸æ˜'
                        }
                        vacant_rooms.append(room_info)
                        print(f"ğŸ  ç©ºå®¤ç™ºè¦‹: {room_info}")
                            
                except Exception as e:
                    print(f"âš ï¸ æˆ¿é—´æƒ…å ±æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            # è¿½åŠ æƒ…å ±ã®å‡¦ç†ï¼ˆäºˆå®šç¾©æƒ…å ±ã‚’å„ªå…ˆã€ãªã‘ã‚Œã°æŠ“å–ï¼‰
            scraped_info = {}
            
            # äºˆå®šç¾©æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯æŠ“å–ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if predefined_info and all(key in predefined_info for key in ['transportation', 'address', 'phone', 'management_years']):
                print(f"ğŸ“‹ äºˆå®šç¾©æƒ…å ±ã‚’ä½¿ç”¨: {predefined_info.get('name', 'ä¸æ˜')}")
                scraped_info = {
                    'transportation': predefined_info['transportation'],
                    'transportation_source': 'äº‹å‰å®šç¾©',
                    'address': predefined_info['address'],
                    'address_source': 'äº‹å‰å®šç¾©',
                    'phone_number': predefined_info['phone'],
                    'phone_source': 'äº‹å‰å®šç¾©',
                    'management_years': predefined_info['management_years'],
                    'management_years_source': 'äº‹å‰å®šç¾©'
                }
            else:
                print(f"ğŸ” ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‹ã‚‰è¿½åŠ æƒ…å ±ã‚’æŠ“å–ä¸­...")
                
                # äº¤é€šæƒ…å ±ã‚’æŠ“å–
                try:
                    transportation_selectors = [
                        'dt:contains("äº¤é€š") + dd',
                        '.access-info',
                        '.transportation',
                        'td:contains("äº¤é€š") + td',
                        'th:contains("äº¤é€š") + td',
                        '.property-access'
                    ]
                    transportation = None
                    for selector in transportation_selectors:
                        try:
                            element = await page.query_selector(selector)
                            if element:
                                transportation = await element.text_content()
                                if transportation and transportation.strip():
                                    transportation = transportation.strip()
                                    break
                        except:
                            continue
                    
                    if not transportation:
                        # å°è¯•ä»é¡µé¢æ–‡æœ¬ä¸­æŸ¥æ‰¾äº¤é€šä¿¡æ¯
                        page_text = await page.text_content('body')
                        if page_text:
                            import re
                            # æŸ¥æ‰¾åŒ…å«"é§…"æˆ–"ç·š"çš„äº¤é€šä¿¡æ¯
                            transport_match = re.search(r'[^\n]*(?:é§…|ç·š)[^\n]*', page_text)
                            if transport_match:
                                transportation = transport_match.group().strip()
                    
                    scraped_info['transportation'] = transportation or 'ä¸æ˜'
                    scraped_info['transportation_source'] = 'ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸æŠ“å–' if transportation else 'ä¸æ˜'
                except Exception as e:
                    scraped_info['transportation'] = 'ä¸æ˜'
                    scraped_info['transportation_source'] = 'ä¸æ˜'
                
                # ä½æ‰€æƒ…å ±ã‚’æŠ“å–
                try:
                    address_selectors = [
                        'dt:contains("æ‰€åœ¨åœ°") + dd',
                        'dt:contains("ä½æ‰€") + dd',
                        '.address',
                        '.location',
                        'td:contains("æ‰€åœ¨åœ°") + td',
                        'th:contains("ä½æ‰€") + td',
                        '.property-address'
                    ]
                    address = None
                    for selector in address_selectors:
                        try:
                            element = await page.query_selector(selector)
                            if element:
                                address = await element.text_content()
                                if address and address.strip():
                                    address = address.strip()
                                    break
                        except:
                            continue
                    
                    scraped_info['address'] = address or 'ä¸æ˜'
                    scraped_info['address_source'] = 'ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸æŠ“å–' if address else 'ä¸æ˜'
                except Exception as e:
                    scraped_info['address'] = 'ä¸æ˜'
                    scraped_info['address_source'] = 'ä¸æ˜'
                
                # é›»è©±ç•ªå·ã‚’æŠ“å–
                try:
                    phone_selectors = [
                        'dt:contains("é›»è©±") + dd',
                        'dt:contains("TEL") + dd',
                        '.phone',
                        '.tel',
                        'td:contains("é›»è©±") + td',
                        'th:contains("TEL") + td',
                        '.contact-phone'
                    ]
                    phone = None
                    for selector in phone_selectors:
                        try:
                            element = await page.query_selector(selector)
                            if element:
                                phone = await element.text_content()
                                if phone and phone.strip():
                                    phone = phone.strip()
                                    break
                        except:
                            continue
                    
                    if not phone:
                        # å°è¯•ä»é¡µé¢æ–‡æœ¬ä¸­æŸ¥æ‰¾ç”µè¯å·ç 
                        page_text = await page.text_content('body')
                        if page_text:
                            import re
                            # æŸ¥æ‰¾ç”µè¯å·ç æ ¼å¼
                            phone_match = re.search(r'(?:é›»è©±|TEL|Tel|tel)[:ï¼š\s]*([0-9\-\(\)]+)', page_text)
                            if phone_match:
                                phone = phone_match.group(1).strip()
                    
                    scraped_info['phone_number'] = phone or 'ä¸æ˜'
                    scraped_info['phone_source'] = 'ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸æŠ“å–' if phone else 'ä¸æ˜'
                except Exception as e:
                    scraped_info['phone_number'] = 'ä¸æ˜'
                    scraped_info['phone_source'] = 'ä¸æ˜'
                
                # ç®¡ç†å¹´æ•°ã‚’æŠ“å–
                try:
                    management_selectors = [
                        'dt:contains("ç®¡ç†å¹´æ•°") + dd',
                        'dt:contains("ç¯‰å¹´") + dd',
                        '.management-years',
                        '.built-year',
                        'td:contains("ç®¡ç†å¹´æ•°") + td',
                        'th:contains("ç¯‰å¹´") + td',
                        '.property-age'
                    ]
                    management_years = None
                    for selector in management_selectors:
                        try:
                            element = await page.query_selector(selector)
                            if element:
                                management_years = await element.text_content()
                                if management_years and management_years.strip():
                                    management_years = management_years.strip()
                                    break
                        except:
                            continue
                    
                    scraped_info['management_years'] = management_years or 'ä¸æ˜'
                    scraped_info['management_years_source'] = 'ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸æŠ“å–' if management_years else 'ä¸æ˜'
                except Exception as e:
                    scraped_info['management_years'] = 'ä¸æ˜'
                    scraped_info['management_years_source'] = 'ä¸æ˜'
            
            return {
                'url': url,
                'property_name': property_name,
                'title': await page.title() if not (predefined_info and predefined_info.get('name')) else property_name,
                'vacant_rooms': vacant_rooms,
                'total_vacant': len(vacant_rooms),
                'phone_number': scraped_info.get('phone_number', 'ä¸æ˜'),
                'phone_source': scraped_info.get('phone_source', 'ä¸æ˜'),
                'transportation': scraped_info.get('transportation', 'ä¸æ˜'),
                'transportation_source': scraped_info.get('transportation_source', 'ä¸æ˜'),
                'address': scraped_info.get('address', 'ä¸æ˜'),
                'address_source': scraped_info.get('address_source', 'ä¸æ˜'),
                'management_years': scraped_info.get('management_years', 'ä¸æ˜'),
                'management_years_source': scraped_info.get('management_years_source', 'ä¸æ˜'),
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'url': url,
                'property_name': predefined_info.get('name') if predefined_info else 'Unknown',
                'title': '',
                'vacant_rooms': [],
                'total_vacant': 0,
                'phone_number': predefined_info.get('phone', 'æœªçŸ¥') if predefined_info else 'æœªçŸ¥',
                'phone_source': 'é¢„å®šä¹‰' if predefined_info and predefined_info.get('phone') else 'æœªçŸ¥',
                'transportation': predefined_info.get('transportation', 'æœªçŸ¥') if predefined_info else 'æœªçŸ¥',
                'transportation_source': 'é¢„å®šä¹‰' if predefined_info and predefined_info.get('transportation') else 'æœªçŸ¥',
                'address': predefined_info.get('address', 'æœªçŸ¥') if predefined_info else 'æœªçŸ¥',
                'address_source': 'é¢„å®šä¹‰' if predefined_info and predefined_info.get('address') else 'æœªçŸ¥',
                'management_years': predefined_info.get('management_years', 'æœªçŸ¥') if predefined_info else 'æœªçŸ¥',
                'management_years_source': 'é¢„å®šä¹‰' if predefined_info and predefined_info.get('management_years') else 'æœªçŸ¥',
                'status': 'failed',
                'error': 'Max retries exceeded'
            }
    
    async def check_single_property(self, browser, url: str, index: int, total: int, predefined_info: Optional[Dict] = None) -> Dict:
        """
        å˜ä¸€ç‰©ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
        
        Args:
            browser: Playwrightãƒ–ãƒ©ã‚¦ã‚¶ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            url: å¯¾è±¡URL
            index: ç¾åœ¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            total: ç·æ•°
            predefined_info: äº‹å‰å®šç¾©ã•ã‚ŒãŸç‰©ä»¶æƒ…å ±è¾æ›¸
            
        Returns:
            ç‰©ä»¶æƒ…å ±è¾æ›¸
        """
        print(f"ğŸ” [{index}/{total}] ãƒã‚§ãƒƒã‚¯ä¸­: {url}")
        
        try:
            page = await browser.new_page()
            
            # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã®ãƒªãƒˆãƒ©ã‚¤ãƒ«ãƒ¼ãƒ—
            for attempt in range(self.max_retries):
                try:
                    print(f"   ğŸ“– ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿è©¦è¡Œ {attempt + 1}/{self.max_retries}...")
                    await page.goto(url, wait_until='networkidle', timeout=30000)
                    await asyncio.sleep(self.delay_seconds)
                    break
                except Exception as e:
                    print(f"   âš ï¸  ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼ˆè©¦è¡Œ {attempt + 1}ï¼‰: {e}")
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    else:
                        print(f"   âŒ ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {url}")
                        return {
                            'url': url,
                            'property_name': predefined_info.get('name') if predefined_info else 'ä¸æ˜ãªç‰©ä»¶',
                            'title': '',
                            'vacant_rooms': [],
                            'total_vacant': 0,
                            'phone_number': predefined_info.get('phone', 'ä¸æ˜') if predefined_info else 'ä¸æ˜',
                            'phone_source': 'äº‹å‰å®šç¾©' if predefined_info and predefined_info.get('phone') else 'ä¸æ˜',
                            'transportation': predefined_info.get('transportation', 'ä¸æ˜') if predefined_info else 'ä¸æ˜',
                            'transportation_source': 'äº‹å‰å®šç¾©' if predefined_info and predefined_info.get('transportation') else 'ä¸æ˜',
                            'address': predefined_info.get('address', 'ä¸æ˜') if predefined_info else 'ä¸æ˜',
                            'address_source': 'äº‹å‰å®šç¾©' if predefined_info and predefined_info.get('address') else 'ä¸æ˜',
                            'management_years': predefined_info.get('management_years', 'ä¸æ˜') if predefined_info else 'ä¸æ˜',
                            'management_years_source': 'äº‹å‰å®šç¾©' if predefined_info and predefined_info.get('management_years') else 'ä¸æ˜',
                            'status': 'failed',
                            'error': 'ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¤±æ•—'
                        }
            
            # æƒ…å ±ã‚’æŠ½å‡º
            result = await self.extract_property_info(page, url, predefined_info)
            await page.close()
            
            if result['status'] == 'success':
                print(f"âœ… [{index}/{total}] æˆåŠŸ: {result['property_name']} ({result['total_vacant']}ä»¶ã®ç©ºå®¤)")
                return result
            else:
                print(f"âš ï¸  [{index}/{total}] æŠ½å‡ºå¤±æ•—: {url}")
                
        except Exception as e:
            print(f"âŒ [{index}/{total}] ã‚¨ãƒ©ãƒ¼: {str(e)}")
            try:
                await page.close()
            except:
                pass
        
        # ã™ã¹ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ãŸå ´åˆ
        return {
            'url': url,
            'property_name': predefined_info.get('name') if predefined_info else 'ä¸æ˜ãªç‰©ä»¶',
            'title': '',
            'vacant_rooms': [],
            'total_vacant': 0,
            'phone_number': predefined_info.get('phone', 'ä¸æ˜') if predefined_info else 'ä¸æ˜',
            'phone_source': 'äº‹å‰å®šç¾©' if predefined_info and predefined_info.get('phone') else 'ä¸æ˜',
            'transportation': predefined_info.get('transportation', 'ä¸æ˜') if predefined_info else 'ä¸æ˜',
            'transportation_source': 'äº‹å‰å®šç¾©' if predefined_info and predefined_info.get('transportation') else 'ä¸æ˜',
            'address': predefined_info.get('address', 'ä¸æ˜') if predefined_info else 'ä¸æ˜',
            'address_source': 'äº‹å‰å®šç¾©' if predefined_info and predefined_info.get('address') else 'ä¸æ˜',
            'management_years': predefined_info.get('management_years', 'ä¸æ˜') if predefined_info else 'ä¸æ˜',
            'management_years_source': 'äº‹å‰å®šç¾©' if predefined_info and predefined_info.get('management_years') else 'ä¸æ˜',
            'status': 'failed',
            'error': 'Max retries exceeded'
        }
    
    async def check_properties(self, url_data: List[Tuple[str, str]]) -> List[Dict]:
        """
        è¤‡æ•°ã®ç‰©ä»¶ã‚’ãƒãƒƒãƒå‡¦ç†ã§ãƒã‚§ãƒƒã‚¯
        
        Args:
            url_data: (URL, ç‰©ä»¶å) ã‚¿ãƒ—ãƒ«ãƒªã‚¹ãƒˆ
            
        Returns:
            çµæœãƒªã‚¹ãƒˆ
        """
        print(f"ğŸš€ {len(url_data)}ä»¶ã®UR-NETç‰©ä»¶ã‚’ãƒãƒƒãƒãƒã‚§ãƒƒã‚¯é–‹å§‹...")
        print(f"â±ï¸  ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”: {self.delay_seconds}ç§’")
        print("=" * 60)
        
        results = []
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=self.headless)
            
            try:
                # å„URLã‚’é †æ¬¡å‡¦ç†
                for i, item in enumerate(url_data, 1):
                    # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã«å¿œã˜ã¦URLã¨æƒ…å ±ã‚’å–å¾—
                    if isinstance(item, dict):
                        url = item.get('url', '')
                        predefined_info = item
                    else:
                        url, name = item
                        predefined_info = {'name': name} if name else None
                    
                    if not url:
                        continue
                    result = await self.check_single_property(browser, url, i, len(url_data), predefined_info)
                    results.append(result)
                    
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãŸã‚ã®é…å»¶
                    if i < len(url_data):
                        print(f"â³ {self.delay_seconds}ç§’å¾…æ©Ÿä¸­...")
                        await asyncio.sleep(self.delay_seconds)
                        
            finally:
                await browser.close()
        
        print(f"âœ… ãƒãƒƒãƒãƒã‚§ãƒƒã‚¯å®Œäº†ï¼ {len(results)}ä»¶å‡¦ç†ã—ã¾ã—ãŸ")
        self.results = results
        return results
    
    def print_results(self, results: List[Dict]):
        """
        æ‰“å°æ ¼å¼åŒ–çš„ç»“æœ
        
        Args:
            results: æ£€æŸ¥ç»“æœåˆ—è¡¨
        """
        print("\n" + "=" * 80)
        print("ğŸ  UR-NET æ‰¹é‡ç©ºæˆ¿æ£€æŸ¥ç»“æœ")
        print("=" * 80)
        
        success_count = sum(1 for r in results if r['status'] == 'success')
        failed_count = len(results) - success_count
        total_vacant = sum(r['total_vacant'] for r in results if r['status'] == 'success')
        
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»æ£€æŸ¥æ•°: {len(results)}")
        print(f"   æˆåŠŸ: {success_count}")
        print(f"   å¤±è´¥: {failed_count}")
        print(f"   æ€»ç©ºæˆ¿æ•°: {total_vacant}")
        print()
        
        # æŒ‰æœ‰æ— ç©ºæˆ¿åˆ†ç»„æ˜¾ç¤º
        properties_with_rooms = [r for r in results if r['status'] == 'success' and r['total_vacant'] > 0]
        properties_without_rooms = [r for r in results if r['status'] == 'success' and r['total_vacant'] == 0]
        failed_properties = [r for r in results if r['status'] != 'success']
        
        # æ˜¾ç¤ºæœ‰ç©ºæˆ¿çš„æˆ¿äº§
        if properties_with_rooms:
            print("ğŸ  æœ‰ç©ºæˆ¿çš„æˆ¿äº§:")
            print("-" * 50)
            for result in properties_with_rooms:
                print(f"\nğŸ“ {result['property_name']}")
                print(f"   ç©ºæˆ¿æ•°é‡: {result['total_vacant']}ä¸ª")
                
                for i, room in enumerate(result['vacant_rooms'], 1):
                    print(f"   ğŸ  ç©ºæˆ¿ {i}:")
                    print(f"      æˆ¿é—´: {room.get('room_name', 'æœªçŸ¥')}")
                    print(f"      ç§Ÿé‡‘: {room.get('rent', 'æœªçŸ¥')}")
                    print(f"      æˆ¿å‹: {room.get('layout', 'æœªçŸ¥')}")
                    print(f"      é¢ç§¯: {room.get('area', 'æœªçŸ¥')}")
                    print(f"      æ¥¼å±‚: {room.get('floor', 'æœªçŸ¥')}")
        
        # æ˜¾ç¤ºæ— ç©ºæˆ¿çš„æˆ¿äº§
        if properties_without_rooms:
            print("\nğŸš« æ— ç©ºæˆ¿çš„æˆ¿äº§:")
            print("-" * 50)
            for result in properties_without_rooms:
                print(f"ğŸ“ {result['property_name']}: ã”ç´¹ä»‹å‡ºæ¥ã‚‹ãŠéƒ¨å±‹ã¯ã”ã–ã„ã¾ã›ã‚“ã€‚")
        
        # æ˜¾ç¤ºå¤±è´¥çš„æˆ¿äº§
        if failed_properties:
            print("\nâŒ æ£€æŸ¥å¤±è´¥çš„æˆ¿äº§:")
            print("-" * 50)
            for result in failed_properties:
                print(f"ğŸ“ {result['url']}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    def find_latest_result_file(self, results_dir: str = "results") -> Optional[str]:
        """
        æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        
        Args:
            results_dir: çµæœãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
        """
        try:
            if not os.path.exists(results_dir):
                return None
                
            # ur_net_results_*.json ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            import glob
            pattern = os.path.join(results_dir, "ur_net_results_*.json")
            result_files = glob.glob(pattern)
            
            if not result_files:
                return None
                
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥æ™‚ã‚’æŠ½å‡ºã—ã¦ã‚½ãƒ¼ãƒˆ
            def extract_timestamp(filepath):
                filename = os.path.basename(filepath)
                # ur_net_results_20251006_231825.json ã‹ã‚‰ 20251006_231825 ã‚’æŠ½å‡º
                import re
                match = re.search(r'ur_net_results_(\d{8}_\d{6})\.json', filename)
                if match:
                    return match.group(1)
                return "00000000_000000"
            
            # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            latest_file = max(result_files, key=extract_timestamp)
            return latest_file
            
        except Exception as e:
            print(f"âš ï¸ æœ€æ–°çµæœãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def compare_results(self, current_results: List[Dict], previous_file: str) -> Dict:
        """
        ç¾åœ¨ã®çµæœã¨å‰å›ã®çµæœã‚’æ¯”è¼ƒ
        
        Args:
            current_results: ç¾åœ¨ã®ãƒã‚§ãƒƒã‚¯çµæœ
            previous_file: å‰å›ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            æ¯”è¼ƒçµæœã‚’å«ã‚€è¾æ›¸
        """
        comparison_result = {
            'has_new_properties': False,
            'new_properties': [],
            'previous_file': previous_file,
            'comparison_summary': {}
        }
        
        try:
            # å‰å›ã®çµæœã‚’èª­ã¿è¾¼ã¿
            with open(previous_file, 'r', encoding='utf-8') as f:
                previous_data = json.load(f)
                previous_results = previous_data.get('results', [])
            
            # ç¾åœ¨ã®ç©ºå®¤ã‚ã‚Šã®ç‰©ä»¶ã‚’å–å¾—
            current_vacant_properties = {}
            for result in current_results:
                if result.get('status') == 'success' and result.get('total_vacant', 0) > 0:
                    url = result.get('url', '')
                    current_vacant_properties[url] = {
                        'property_name': result.get('property_name', ''),
                        'total_vacant': result.get('total_vacant', 0),
                        'vacant_rooms': result.get('vacant_rooms', [])
                    }
            
            # å‰å›ã®ç©ºå®¤ã‚ã‚Šã®ç‰©ä»¶ã‚’å–å¾—
            previous_vacant_properties = {}
            for result in previous_results:
                if result.get('status') == 'success' and result.get('total_vacant', 0) > 0:
                    url = result.get('url', '')
                    previous_vacant_properties[url] = {
                        'property_name': result.get('property_name', ''),
                        'total_vacant': result.get('total_vacant', 0),
                        'vacant_rooms': result.get('vacant_rooms', [])
                    }
            
            # æ–°ã—ã„ç©ºå®¤ç‰©ä»¶ã‚’æ¤œå‡º
            new_vacant_urls = set(current_vacant_properties.keys()) - set(previous_vacant_properties.keys())
            
            # æ—¢å­˜ç‰©ä»¶ã§ç©ºå®¤æ•°ãŒå¢—åŠ ã—ãŸå ´åˆã‚‚æ–°è¦ã¨ã¿ãªã™
            increased_vacant_urls = []
            for url in current_vacant_properties:
                if url in previous_vacant_properties:
                    current_count = current_vacant_properties[url]['total_vacant']
                    previous_count = previous_vacant_properties[url]['total_vacant']
                    if current_count > previous_count:
                        increased_vacant_urls.append(url)
            
            # æ–°è¦ç‰©ä»¶æƒ…å ±ã‚’åé›†
            all_new_urls = list(new_vacant_urls) + increased_vacant_urls
            for url in all_new_urls:
                if url in current_vacant_properties:
                    comparison_result['new_properties'].append({
                        'url': url,
                        'property_name': current_vacant_properties[url]['property_name'],
                        'total_vacant': current_vacant_properties[url]['total_vacant'],
                        'vacant_rooms': current_vacant_properties[url]['vacant_rooms'],
                        'change_type': 'new' if url in new_vacant_urls else 'increased'
                    })
            
            # æ–°è¦ç‰©ä»¶ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š
            comparison_result['has_new_properties'] = len(comparison_result['new_properties']) > 0
            
            # æ¯”è¼ƒã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
            comparison_result['comparison_summary'] = {
                'previous_vacant_count': len(previous_vacant_properties),
                'current_vacant_count': len(current_vacant_properties),
                'new_vacant_properties': len(new_vacant_urls),
                'increased_vacant_properties': len(increased_vacant_urls),
                'total_new_changes': len(comparison_result['new_properties'])
            }
            
            print(f"ğŸ“Š çµæœæ¯”è¼ƒå®Œäº†:")
            print(f"   å‰å›ç©ºå®¤ç‰©ä»¶æ•°: {len(previous_vacant_properties)}")
            print(f"   ä»Šå›ç©ºå®¤ç‰©ä»¶æ•°: {len(current_vacant_properties)}")
            print(f"   æ–°è¦ç©ºå®¤ç‰©ä»¶: {len(new_vacant_urls)}")
            print(f"   ç©ºå®¤å¢—åŠ ç‰©ä»¶: {len(increased_vacant_urls)}")
            print(f"   ãƒ¡ãƒ¼ãƒ«é€ä¿¡å¿…è¦: {'ã¯ã„' if comparison_result['has_new_properties'] else 'ã„ã„ãˆ'}")
            
        except Exception as e:
            print(f"âš ï¸ çµæœæ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å®‰å…¨ã®ãŸã‚ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚’æ¨å¥¨
            comparison_result['has_new_properties'] = True
            comparison_result['comparison_summary']['error'] = str(e)
        
        return comparison_result
    
    def should_send_email(self, results: List[Dict], results_dir: str = "results") -> Tuple[bool, Dict]:
        """
        ãƒ¡ãƒ¼ãƒ«é€ä¿¡ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        
        Args:
            results: ç¾åœ¨ã®ãƒã‚§ãƒƒã‚¯çµæœ
            results_dir: çµæœãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            (é€ä¿¡å¿…è¦ãƒ•ãƒ©ã‚°, åˆ¤å®šè©³ç´°æƒ…å ±)
        """
        decision_info = {
            'should_send': False,
            'reason': '',
            'is_first_run': False,
            'comparison_result': None
        }
        
        # æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        latest_file = self.find_latest_result_file(results_dir)
        
        if not latest_file:
            # åˆå›å®Ÿè¡Œã®å ´åˆ
            decision_info['should_send'] = True
            decision_info['reason'] = 'åˆå›å®Ÿè¡Œã®ãŸã‚'
            decision_info['is_first_run'] = True
            print("ğŸ“§ åˆå›å®Ÿè¡Œæ¤œå‡º - ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚’å®Ÿè¡Œã—ã¾ã™")
        else:
            # å‰å›çµæœã¨æ¯”è¼ƒ
            print(f"ğŸ” å‰å›çµæœã¨æ¯”è¼ƒä¸­: {latest_file}")
            comparison_result = self.compare_results(results, latest_file)
            decision_info['comparison_result'] = comparison_result
            
            if comparison_result['has_new_properties']:
                decision_info['should_send'] = True
                decision_info['reason'] = f"æ–°è¦ç©ºå®¤ç‰©ä»¶ {len(comparison_result['new_properties'])} ä»¶æ¤œå‡º"
                print(f"ğŸ“§ æ–°è¦ç‰©ä»¶æ¤œå‡º - ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚’å®Ÿè¡Œã—ã¾ã™")
            else:
                decision_info['should_send'] = False
                decision_info['reason'] = 'æ–°è¦ç©ºå®¤ç‰©ä»¶ãªã—'
                print("ğŸ“§ æ–°è¦ç‰©ä»¶ãªã— - ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        
        return decision_info['should_send'], decision_info

    def save_results(self, results: List[Dict], output_format: str = 'json', output_path: Optional[str] = None):
        """
        çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            results: ãƒã‚§ãƒƒã‚¯çµæœãƒªã‚¹ãƒˆ
            output_format: å‡ºåŠ›å½¢å¼ ('json', 'csv', 'txt')
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
        """
        if not output_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            results_dir = "/app/results" if os.path.exists("/app") else "results"
            os.makedirs(results_dir, exist_ok=True)
            # ä½¿ç”¨ä¸ shell è„šæœ¬åŒ¹é…çš„æ–‡ä»¶åæ ¼å¼
            output_path = os.path.join(results_dir, f"ur_net_results_{timestamp}.{output_format}")
        
        print(f"ğŸ’¾ çµæœã‚’ä¿å­˜ä¸­: {output_path}")
        
        try:
            if output_format == 'json':
                result_data = {
                    'timestamp': datetime.now().isoformat(),
                    'total_checked': len(results),
                    'total_vacant_rooms': sum(r['total_vacant'] for r in results if r['status'] == 'success'),
                    'results': results
                }
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, ensure_ascii=False, indent=2)
                    
            elif output_format == 'csv':
                import csv
                with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:
                    if results:
                        writer = csv.DictWriter(f, fieldnames=results[0].keys())
                        writer.writeheader()
                        writer.writerows(results)
                        
            elif output_format == 'txt':
                with open(output_path, 'w', encoding='utf-8') as f:
                    for result in results:
                        f.write(f"ç‰©ä»¶å: {result.get('property_name', 'ä¸æ˜')}\n")
                        f.write(f"URL: {result.get('url', 'ä¸æ˜')}\n")
                        f.write(f"ç©ºå®¤æ•°: {result.get('total_vacant', 0)}ä»¶\n")
                        f.write(f"çŠ¶æ…‹: {result.get('status', 'ä¸æ˜')}\n")
                        f.write(f"é›»è©±ç•ªå·: {result.get('phone_number', 'ä¸æ˜')}\n")
                        f.write(f"äº¤é€š: {result.get('transportation', 'ä¸æ˜')}\n")
                        f.write(f"ä½æ‰€: {result.get('address', 'ä¸æ˜')}\n")
                        f.write(f"ç®¡ç†å¹´æ•°: {result.get('management_years', 'ä¸æ˜')}\n")
                        f.write(f"æ›´æ–°æ—¥æ™‚: {result.get('last_updated', 'ä¸æ˜')}\n")
                        
                        if result.get('vacant_rooms'):
                            f.write("ç©ºå®¤è©³ç´°:\n")
                            for room in result['vacant_rooms']:
                                f.write(f"  - {room}\n")
                        f.write("-" * 50 + "\n\n")
            
            print(f"âœ… çµæœã‚’æ­£å¸¸ã«ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
            
        except Exception as e:
            print(f"âŒ çµæœã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def parse_urls_from_text(text: str) -> List[str]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰UR-NET URLã‚’æŠ½å‡º
    
    Args:
        text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        URLãƒªã‚¹ãƒˆ
    """
    # UR-NET URLãƒ‘ã‚¿ãƒ¼ãƒ³
    url_pattern = r'https?://www\.ur-net\.go\.jp/[^\s]+'
    urls = re.findall(url_pattern, text)
    return urls

def parse_urls_from_csv(csv_file: str) -> List[Dict]:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰URLã¨ç‰©ä»¶æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        csv_file: CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        ç‰©ä»¶æƒ…å ±è¾æ›¸ãƒªã‚¹ãƒˆ
    """
    import csv
    
    url_data = []
    print(f"ğŸ“„ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {csv_file}")
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            # æœ€åˆã®è¡Œã‚’ç¢ºèªã—ã¦ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            first_line = f.readline().strip()
            f.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
            
            print(f"ğŸ“„ æœ€åˆã®è¡Œ: {first_line}")
            
            # urls.txtå½¢å¼ã®ç‰¹åˆ¥å‡¦ç†ï¼ˆNo.,ç‰©ä»¶å,å¯¾è±¡ç©ºå®¤æ•°,æœ€å¯„é§…,ä½æ‰€,é›»è©±ç•ªå·,ç®¡ç†å¹´æ•°,URLï¼‰
            if 'No.,ç‰©ä»¶å,å¯¾è±¡ç©ºå®¤æ•°,æœ€å¯„é§…,ä½æ‰€,é›»è©±ç•ªå·,ç®¡ç†å¹´æ•°,URL' in first_line:
                print("ğŸ“„ urls.txtå½¢å¼ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
                reader = csv.reader(f)
                next(reader)  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                for row_num, row in enumerate(reader, 2):  # 2è¡Œç›®ã‹ã‚‰é–‹å§‹
                    print(f"ğŸ“„ è¡Œ{row_num}: {len(row)}åˆ— - {row}")
                    if len(row) >= 8:  # 8åˆ—å¿…è¦
                        url = row[7].strip() if len(row) > 7 else ""  # URLã¯8ç•ªç›®ã®åˆ—ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹7ï¼‰
                        if url and url.startswith('http'):
                            info = {
                                'url': url,
                                'name': row[1].strip() if len(row) > 1 else 'ä¸æ˜',  # ç‰©ä»¶å
                                'transportation': row[3].strip() if len(row) > 3 else 'ä¸æ˜',  # æœ€å¯„é§…
                                'address': row[4].strip() if len(row) > 4 else 'ä¸æ˜',  # ä½æ‰€
                                'phone': row[5].strip() if len(row) > 5 else 'ä¸æ˜',  # é›»è©±ç•ªå·
                                'management_years': row[6].strip() if len(row) > 6 else 'ä¸æ˜'  # ç®¡ç†å¹´æ•°
                            }
                            url_data.append(info)
                            print(f"âœ… èª­ã¿è¾¼ã¿æˆåŠŸ: {info['name']} - {url}")
                            print(f"   äº¤é€š: {info['transportation']}")
                            print(f"   ä½æ‰€: {info['address']}")
                            print(f"   é›»è©±: {info['phone']}")
                            print(f"   ç®¡ç†å¹´æ•°: {info['management_years']}")
                return url_data
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãªã„å ´åˆã¯ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã§å‡¦ç†
            if not first_line.startswith('url,') and not first_line.startswith('URL,') and not first_line.startswith('name,'):
                print("ğŸ“„ ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ã—ã¾ã™")
                reader = csv.reader(f)
                for row_num, row in enumerate(reader):
                    print(f"ğŸ“„ è¡Œ{row_num+1}: {len(row)}åˆ— - {row}")
                    if len(row) >= 8:  # å°‘ãªãã¨ã‚‚8åˆ—å¿…è¦
                        url = row[7] if len(row) > 7 else ""  # URLã¯8ç•ªç›®ã®åˆ—ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹7ï¼‰
                        if url and url.startswith('http'):
                            info = {'url': url}
                            if len(row) > 0: info['name'] = row[0].strip()
                            if len(row) > 5: info['phone'] = row[5].strip()
                            if len(row) > 3: info['transportation'] = row[3].strip()
                            if len(row) > 4: info['address'] = row[4].strip()
                            if len(row) > 6: info['management_years'] = row[6].strip()
                            url_data.append(info)
                            print(f"âœ… èª­ã¿è¾¼ã¿æˆåŠŸ: {info.get('name', 'ä¸æ˜')} - {url}")
                return url_data
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚ã‚‹å ´åˆã¯DictReaderã‚’ä½¿ç”¨
            reader = csv.DictReader(f)
            print(f"ğŸ“„ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å: {reader.fieldnames}")
            for row_num, row in enumerate(reader):
                # URLã‚«ãƒ©ãƒ ã‚’æ¢ã™
                url = None
                for key in ['url', 'URL', 'ãƒªãƒ³ã‚¯', 'link']:
                    if key in row and row[key]:
                        url = row[key].strip()
                        break
                
                if url:
                    # ç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡º
                    info = {'url': url}
                    
                    # åç§°ã‚«ãƒ©ãƒ ã‚’æ¢ã™
                    for key in ['name', 'åç§°', 'ç‰©ä»¶å', 'property_name', 'å›£åœ°å']:
                        if key in row and row[key]:
                            info['name'] = row[key].strip()
                            break
                    
                    # é›»è©±ç•ªå·ã‚«ãƒ©ãƒ ã‚’æ¢ã™
                    for key in ['phone', 'é›»è©±', 'é›»è©±ç•ªå·', 'tel', 'TEL']:
                        if key in row and row[key]:
                            info['phone'] = row[key].strip()
                            break
                    
                    # äº¤é€šã‚«ãƒ©ãƒ ã‚’æ¢ã™
                    for key in ['transportation', 'äº¤é€š', 'äº¤é€šæ©Ÿé–¢', 'access', 'æœ€å¯„é§…']:
                        if key in row and row[key]:
                            info['transportation'] = row[key].strip()
                            break
                    
                    # ä½æ‰€ã‚«ãƒ©ãƒ ã‚’æ¢ã™
                    for key in ['address', 'ä½æ‰€', 'æ‰€åœ¨åœ°', 'location']:
                        if key in row and row[key]:
                            info['address'] = row[key].strip()
                            break
                    
                    # ç®¡ç†å¹´æ•°ã‚«ãƒ©ãƒ ã‚’æ¢ã™
                    for key in ['management_years', 'ç®¡ç†å¹´æ•°', 'years', 'å¹´æ•°']:
                        if key in row and row[key]:
                            info['management_years'] = row[key].strip()
                            break
                    
                    url_data.append(info)
                    print(f"ğŸ“„ è¡Œ{row_num+1}: {info.get('name', 'ä¸æ˜')} - {url}")
        
        print(f"ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰{len(url_data)}ä»¶ã®ç‰©ä»¶æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return url_data
        
    except FileNotFoundError:
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_file}")
        return []
    except Exception as e:
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return []

async def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•° - ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    """
    parser = argparse.ArgumentParser(
        description='UR-NETãƒãƒƒãƒç©ºå®¤ãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # URLãƒªã‚¹ãƒˆã‚’ç›´æ¥æŒ‡å®š
  python ur_net_batch_property_checker.py -u "https://www.ur-net.go.jp/..." "https://www.ur-net.go.jp/..."
  
  # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰URLã‚’èª­ã¿è¾¼ã‚€
  python ur_net_batch_property_checker.py -f urls.txt
  
  # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰©ä»¶æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
  python ur_net_batch_property_checker.py -c properties.csv
  
  # å‡ºåŠ›å½¢å¼ã‚’æŒ‡å®š
  python ur_net_batch_property_checker.py -u "https://..." -o csv -p results.csv
  
  # é…å»¶æ™‚é–“ã‚’è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ2ç§’ï¼‰
  python ur_net_batch_property_checker.py -u "https://..." -d 3
  
  # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã‚’è¡¨ç¤ºï¼‰
  python ur_net_batch_property_checker.py -u "https://..." --no-headless
        """
    )
    
    # å¼•æ•°ã‚’å®šç¾©
    parser.add_argument('-u', '--urls', nargs='+', help='UR-NETç‰©ä»¶URL')
    parser.add_argument('-f', '--file', help='URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('-c', '--csv', help='ç‰©ä»¶æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('-o', '--output-format', choices=['json', 'csv', 'txt'], default='json', help='å‡ºåŠ›å½¢å¼')
    parser.add_argument('-p', '--output-path', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('-d', '--delay', type=float, default=2.0, help='ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã®é…å»¶æ™‚é–“ï¼ˆç§’ï¼‰')
    parser.add_argument('--max-retries', type=int, default=5, help='æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°')
    parser.add_argument('--no-headless', action='store_true', help='ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›')
    
    args = parser.parse_args()
    
    # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
    if args.verbose:
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    else:
        logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # URLãƒªã‚¹ãƒˆã‚’åé›†
    url_data = []
    
    if args.urls:
        # ç›´æ¥URLã‚’æŒ‡å®š
        for url in args.urls:
            url_data.append({'url': url})
        print(f"ğŸ“‹ {len(url_data)}ä»¶ã®URLã‚’ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    elif args.file:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
        try:
            with open(args.file, 'r', encoding='utf-8') as f:
                content = f.read()
                urls = parse_urls_from_text(content)
                url_data = [{'url': url} for url in urls]
            print(f"ğŸ“„ {args.file}ã‹ã‚‰{len(url_data)}ä»¶ã®URLã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return
    
    elif args.csv:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
        url_data = parse_urls_from_csv(args.csv)
        if not url_data:
            print("âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
            return
    
    else:
        print("âŒ URLã€ãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        parser.print_help()
        return
    
    if not url_data:
        print("âŒ æœ‰åŠ¹ãªURLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    print(f"\nğŸ¯ åˆè¨ˆ{len(url_data)}ä»¶ã®ç‰©ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™")
    print(f"â±ï¸  é…å»¶æ™‚é–“: {args.delay}ç§’")
    print(f"ğŸ”„ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°: {args.max_retries}")
    print(f"ğŸ‘» ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: {'ç„¡åŠ¹' if args.no_headless else 'æœ‰åŠ¹'}")
    print("=" * 60)
    
    # ãƒãƒƒãƒãƒã‚§ãƒƒã‚«ãƒ¼ã‚’ä½œæˆ
    checker = URNetBatchChecker(
        delay_seconds=args.delay,
        max_retries=args.max_retries,
        headless=not args.no_headless
    )
    
    try:
        # ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
        urls = [item['url'] for item in url_data]
        results = await checker.check_properties(url_data)
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        successful = sum(1 for r in results if r['status'] == 'success')
        failed = sum(1 for r in results if r['status'] == 'failed')
        total_vacant = sum(r.get('total_vacant', 0) for r in results if r['status'] == 'success')
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ãƒã‚§ãƒƒã‚¯çµæœã‚µãƒãƒªãƒ¼:")
        print(f"  âœ… æˆåŠŸ: {successful}ä»¶")
        print(f"  âŒ å¤±æ•—: {failed}ä»¶")
        print(f"  ğŸ  ç·ç©ºå®¤æ•°: {total_vacant}ä»¶")
        print("=" * 60)
        
        # çµæœã‚’ä¿å­˜
        checker.save_results(results, args.output_format, args.output_path)
        
        # ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã®åˆ¤å®š
        should_send, email_info = checker.should_send_email(results)
        if should_send:
            print(f"\nğŸ“§ ãƒ¡ãƒ¼ãƒ«é€ä¿¡æ¡ä»¶ã‚’æº€ãŸã—ã¾ã—ãŸ: {email_info['reason']}")
            if email_info.get('new_properties'):
                print(f"   æ–°è¦ç‰©ä»¶æ•°: {len(email_info['new_properties'])}")
            if email_info.get('increased_properties'):
                print(f"   ç©ºå®¤å¢—åŠ ç‰©ä»¶æ•°: {len(email_info['increased_properties'])}")
            print("   ãƒ¡ãƒ¼ãƒ«é€ä¿¡å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        else:
            print(f"\nğŸ“§ ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—: {email_info['reason']}")
        
        # ç©ºå®¤ã‚ã‚Šç‰©ä»¶ã‚’è¡¨ç¤º
        vacant_properties = [r for r in results if r.get('total_vacant', 0) > 0]
        if vacant_properties:
            print(f"\nğŸ‰ ç©ºå®¤ã‚ã‚Šç‰©ä»¶ ({len(vacant_properties)}ä»¶):")
            for prop in vacant_properties:
                print(f"  ğŸ¢ {prop['property_name']}: {prop['total_vacant']}ä»¶ã®ç©ºå®¤")
                print(f"     URL: {prop['url']}")
                print(f"     é›»è©±: {prop.get('phone_number', 'ä¸æ˜')}")
                print(f"     äº¤é€š: {prop.get('transportation', 'ä¸æ˜')}")
                print()
        else:
            print("\nğŸ˜” ç©ºå®¤ã‚ã‚Šç‰©ä»¶ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    # Windowsã§å®Ÿè¡Œã™ã‚‹å ´åˆã®ã‚¨ãƒ©ãƒ¼å¯¾ç­–
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
